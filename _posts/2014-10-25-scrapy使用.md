---
layout: post 
title: "scrapy使用"
description: ""
category: oths
tags: []
---

最近由于需要一个能包含常见应用分类的库，所以在别人的推荐下使用scrapy对wandoujia市场上的应用进行了抓取。

[scrapy](http://scrapy-chs.readthedocs.org/zh_CN/latest/intro/tutorial.html)大致是一个python爬虫的框架，使用者只需编写少量代码就可以使用它来完成具体的工作了。对于这个框架，网上的中文资料似乎不多，需要自己摸索。在mac上安装这个框架还是很简单的，简单执行
`pip install scrapy`即可。对于框架的详细使用，参见上面的链接，这里只记录我在使用过程中遇到的几个问题。

1. 使用`scrapy --help`可以方便的查看scrapy支持的使用，我只使用了`crawl|genspider|shell|startproject`几条命令，具体子命令的功能使用`scrapy <command> -h`进行查看。
2. scrapy自带了一个很方便的shell环境调试功能，类似与ipython之对于python的关系。在使用这个功能前，需要确保安装了ipython环境，然后使用`scrapy shell http://xxx`；进入scrapy的shell环境，可以实时对自己的想法进行实验，很实用的功能。
3. 由于wandoujia市场上使用了js来生成一些页面，所以我使用了selenium这个python库模拟了浏览器的行为。结果在使用这个库的时候，遇到了一些问题，在使用如下代码时，找不到Chrome驱动器：

	`from selenium import webdriver`
	
	` webdriver.Chrome()`
出现的错误类似：
`WebDriverException: Message: 'ChromeDriver executable needs to be available in the path.Please download from http://chromedriver.storage.googleapis.com/index.html                and read up at http://code.google.com/p/selenium/wiki/ChromeDriver'`
在google了一圈之后发现没有64位的ChromeDriver版本，其实在错误信息里已经有答案了，到chromedriver的下载链接里下载32位的版本即可。解压到某个位置后，需要在`webdriver.Chrome()`中指定，可以参考[这里](http://stackoverflow.com/questions/8255929/running-webdriver-chrome-with-selenium)。为了避免麻烦，我在`.profile`中设置了`webdriver.chrome.driver`的环境变量，由于这个环境变量中带点，设置有些不一样，使用如下命令行就可以了：
`env 'webdriver.chrome.driver'="/Users/j0y/other_tools/chromedriver" &>/dev/null`。
4. 在使用这个框架时，大部分情况是在使用其Selector来提取相应的xpath，Chrome浏览器对于确认xpath有很方便的手段，要善于利用。

ps:代码提交在[这里](https://github.com/jiych/wdj_spider)。